import cv2
import numpy as np
import easyocr
import json
from ultralytics import YOLO
import os  


MODEL_PATH = r"C:\Users\user\Downloads\parser-for-rag\parser-for-rag\yolo\runs\detect\train4\weights\best.pt"
IMAGE_PATH = r"C:\Users\user\Downloads\parser-for-rag\parser-for-rag\yolo\dataset\images\val\20.png"

OUTPUT_DIR = r"C:\Users\user\Downloads\detection_output" # ê²°ê³¼ë¬¼ì´ ì €ì¥ë  ê¸°ë³¸ í´ë”
VISUALIZED_IMAGE_SAVE_PATH = os.path.join(OUTPUT_DIR, "detection_result_visualized-20.png") # ì‹œê°í™”ëœ ì „ì²´ ì´ë¯¸ì§€
JSON_SAVE_PATH = os.path.join(OUTPUT_DIR, "detection_results-20.json") # JSON ê²°ê³¼ íŒŒì¼
CROPPED_OBJECTS_DIR = os.path.join(OUTPUT_DIR, "cropped_objects")   # ì˜ë¼ë‚¸ ê°ì²´ ì´ë¯¸ì§€ ì €ì¥ í´ë”

CONFIDENCE_THRESHOLD = 0.05     # ê°ì²´ íƒì§€ ìµœì†Œ ì‹ ë¢°ë„
TEXT_CONFIDENCE_THRESHOLD = 0.1 # OCR í…ìŠ¤íŠ¸ ìµœì†Œ ì‹ ë¢°ë„
MIN_BOX_AREA = 25               # ë…¸ì´ì¦ˆë¡œ ê°„ì£¼í•  ìµœì†Œ ë°•ìŠ¤ ë©´ì 

os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(CROPPED_OBJECTS_DIR, exist_ok=True)
print(f"ê²°ê³¼ ì €ì¥ í´ë”: '{OUTPUT_DIR}'")

print("EasyOCR ëª¨ë¸ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤...")
try:
    reader = easyocr.Reader(['ko', 'en'], gpu=True)
    print("EasyOCR ë¡œë”© ì™„ë£Œ (GPU ì‚¬ìš©).")
except Exception as e:
    print(f"GPUë¡œ EasyOCR ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. CPUë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
    reader = easyocr.Reader(['ko', 'en'], gpu=False)
    print("EasyOCR ë¡œë”© ì™„ë£Œ (CPU ì‚¬ìš©).")

print(f"YOLOv8 ëª¨ë¸ì„ '{MODEL_PATH}'ì—ì„œ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤...")
try:
    model = YOLO(MODEL_PATH)
    print(f"ëª¨ë¸ì— ì •ì˜ëœ í´ë˜ìŠ¤ë“¤: {model.names}")
    print("YOLOv8 ëª¨ë¸ ë¡œë”© ì™„ë£Œ.")
except Exception as e:
    print(f"YOLOv8 ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    exit()

def get_box_center(box):
    """Bounding Boxì˜ ì¤‘ì‹¬ì ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    x1, y1, x2, y2 = box
    return int((x1 + x2) / 2), int((y1 + y2) / 2)

def get_box_area(box):
    """Bounding Boxì˜ ë©´ì ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    x1, y1, x2, y2 = box
    return (x2 - x1) * (y2 - y1)

def calculate_iou(box1, box2):
    """ë‘ ë°•ìŠ¤ ê°„ì˜ IoUë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    x1, y1, x2, y2 = box1
    x1_2, y1_2, x2_2, y2_2 = box2

    inter_x1 = max(x1, x1_2)
    inter_y1 = max(y1, y1_2)
    inter_x2 = min(x2, x2_2)
    inter_y2 = min(y2, y2_2)

    if inter_x2 <= inter_x1 or inter_y2 <= inter_y1:
        return 0.0

    inter_area = (inter_x2 - inter_x1) * (inter_y2 - inter_y1)
    box1_area = (x2 - x1) * (y2 - y1)
    box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)
    union_area = box1_area + box2_area - inter_area

    return inter_area / union_area if union_area > 0 else 0.0

def non_max_suppression_custom(detections, iou_threshold=0.5):
    """ì¤‘ë³µ íƒì§€ ì œê±°ë¥¼ ìœ„í•œ NMS ì ìš©"""
    if not detections:
        return []

    sorted_detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)
    keep = []

    for det1 in sorted_detections:
        should_keep = True
        for det2 in keep:
            if det1['original_class'] == det2['original_class']:
                if calculate_iou(det1['box'], det2['box']) > iou_threshold:
                    should_keep = False
                    break
        if should_keep:
            keep.append(det1)

    return keep

def detect_objects_yolo(image, model, conf_threshold=CONFIDENCE_THRESHOLD, min_area=MIN_BOX_AREA):
    """YOLOë¥¼ ì‚¬ìš©í•œ ê°ì²´ íƒì§€"""
    print(f"\n--- ê°ì²´ íƒì§€ ì‹œì‘ (ì‹ ë¢°ë„: {conf_threshold}, ìµœì†Œë©´ì : {min_area}) ---")
    results = model(image, conf=conf_threshold, iou=0.45, verbose=False)

    all_detections = []
    print("\nğŸ” YOLO ì›ì‹œ íƒì§€ ê²°ê³¼:")

    for result in results:
        boxes = result.boxes
        if boxes is None:
            print("  - íƒì§€ëœ ë°•ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue

        print(f"  - ì´ {len(boxes)} ê°œì˜ ì›ì‹œ íƒì§€ ê²°ê³¼")

        for i in range(len(boxes)):
            box = [int(c) for c in boxes.xyxy[i].cpu().numpy()]
            confidence = float(boxes.conf[i].cpu().numpy())
            class_id = int(boxes.cls[i])
            class_name = model.names.get(class_id, 'unknown')
            box_area = get_box_area(box)

            print(f"    [{i}] í´ë˜ìŠ¤: '{class_name}' (ID: {class_id}), ì‹ ë¢°ë„: {confidence:.3f}, ë©´ì : {box_area}")

            if box_area < min_area:
                print(f"         âŒ ë©´ì ì´ ë„ˆë¬´ ì‘ì•„ì„œ ì œì™¸ë¨")
                continue

            all_detections.append({
                'box': box,
                'confidence': confidence,
                'original_class': class_name,
                'class_id': class_id
            })
            print(f"         âœ… íƒì§€ ëª©ë¡ì— ì¶”ê°€ë¨")

    print(f"\nğŸ“Š ë©´ì  í•„í„°ë§ í›„ íƒì§€ ìˆ˜: {len(all_detections)}")

    class_count = {}
    for det in all_detections:
        cls = det['original_class']
        class_count[cls] = class_count.get(cls, 0) + 1

    print("\nğŸ“ˆ í´ë˜ìŠ¤ë³„ íƒì§€ ë¶„í¬ (NMS ì „):")
    for cls, count in class_count.items():
        print(f"  - {cls}: {count}ê°œ")

    filtered_detections = non_max_suppression_custom(all_detections, iou_threshold=0.4)
    print(f"\nğŸ”§ NMS í›„ íƒì§€ ìˆ˜: {len(filtered_detections)}")

    final_detections = {'pointers': [], 'arrows': [], 'target_objects': []}

    print("\nğŸ·ï¸ í´ë˜ìŠ¤ ë§¤í•‘ ê³¼ì •:")
    for det in filtered_detections:
        name_lower = det['original_class'].lower()
        print(f"  - ì›ë³¸ í´ë˜ìŠ¤: '{det['original_class']}' -> ì†Œë¬¸ì: '{name_lower}'")

        mapped = False
        if 'pointer' in name_lower or 'point' in name_lower:
            final_detections['pointers'].append(det)
            print(f"    âœ… pointersì— ë§¤í•‘ë¨")
            mapped = True
        elif 'arrow' in name_lower:
            final_detections['arrows'].append(det)
            print(f"    âœ… arrowsì— ë§¤í•‘ë¨")
            mapped = True
        elif 'target' in name_lower or 'object' in name_lower:
            final_detections['target_objects'].append(det)
            print(f"    âœ… target_objectsì— ë§¤í•‘ë¨")
            mapped = True

        if not mapped:
            print(f"    âŒ ë§¤í•‘ë˜ì§€ ì•ŠìŒ - ì•Œ ìˆ˜ ì—†ëŠ” í´ë˜ìŠ¤")

    for category in final_detections:
        if final_detections[category]:
            original_count = len(final_detections[category])
            final_detections[category] = non_max_suppression_custom(
                final_detections[category], iou_threshold=0.3)
            if original_count != len(final_detections[category]):
                print(f"ğŸ¯ {category} NMS: {original_count} -> {len(final_detections[category])}")

    return final_detections

def recognize_pointer_text(image, pointer_detections):
    """í¬ì¸í„° í…ìŠ¤íŠ¸ OCR"""
    print("\n--- í¬ì¸í„° í…ìŠ¤íŠ¸ OCR ì‹œì‘ ---")
    if not pointer_detections:
        print("  - í¬ì¸í„°ê°€ ì—†ì–´ì„œ OCRì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    for i, p_det in enumerate(pointer_detections):
        x1, y1, x2, y2 = p_det['box']
        padding = 10
        crop_img = image[max(0, y1-padding):min(image.shape[0], y2+padding),
                         max(0, x1-padding):min(image.shape[1], x2+padding)]

        if crop_img.size == 0:
            p_det.update({'text': 'CROP_ERROR', 'text_confidence': 0.0})
            continue

        gray = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(gray)

        results = reader.readtext(enhanced, detail=True, paragraph=False)
        if results:
            best_res = max(results, key=lambda x: x[2])
            text, confidence = best_res[1].strip(), best_res[2]
            p_det['text'] = text if confidence >= TEXT_CONFIDENCE_THRESHOLD else 'N/A'
            p_det['text_confidence'] = confidence
        else:
            p_det.update({'text': 'NO_TEXT', 'text_confidence': 0.0})

        print(f"  - Pointer {i}: '{p_det['text']}' (ì‹ ë¢°ë„: {p_det.get('text_confidence', 0):.3f})")

def visualize_detections(image, detections):
    """íƒì§€ëœ ê°ì²´ë“¤ì„ ì‹œê°í™”"""
    vis_image = image.copy()
    colors = {
        'pointers': (255, 100, 100),
        'arrows': (100, 255, 100),
        'target_objects': (100, 100, 255)
    }

    print("\n--- ì‹œê°í™” ì‹œì‘ ---")

    for category, items in detections.items():
        color = colors.get(category, (128, 128, 128))
        print(f"\nğŸ“ {category.replace('_', ' ').capitalize()} ì‹œê°í™”:")

        for i, item in enumerate(items):
            x1, y1, x2, y2 = item['box']

            cv2.rectangle(vis_image, (x1, y1), (x2, y2), color, 1)

            if category == 'pointers' and 'text' in item:
                label = f"{category[:-1]}_{i}: {item['text']} ({item['confidence']:.2f})"
            else:
                label = f"{category[:-1]}_{i} ({item['confidence']:.2f})"

            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
            cv2.rectangle(vis_image, (x1, y1 - 20), (x1 + label_size[0] + 4, y1), color, -1)

            cv2.putText(vis_image, label, (x1 + 2, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            center = get_box_center(item['box'])
            cv2.circle(vis_image, center, 3, color, -1)

            print(f"  - {category[:-1]}_{i}: {item['original_class']} (ì‹ ë¢°ë„: {item['confidence']:.3f})")

    return vis_image


def save_extracted_objects(original_image, detections, json_data, output_dir):
    """íƒì§€ëœ ê°ì²´ë“¤ì„ ê°œë³„ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì˜ë¼ë‚´ì–´ ì €ì¥í•©ë‹ˆë‹¤."""
    print("\n--- íƒì§€ëœ ê°ì²´ ì´ë¯¸ì§€ ì¶”ì¶œ ë° ì €ì¥ ì‹œì‘ ---")
    print(f"  - ì €ì¥ ê²½ë¡œ: {output_dir}")

    for category, items in json_data.items():
        for item in items:
            obj_id = item['id']
            x1, y1, x2, y2 = item['box']

            filename = f"{obj_id}.png"
            save_path = os.path.join(output_dir, filename)

            cropped_img = original_image[y1:y2, x1:x2]

            if cropped_img.size == 0:
                print(f"    - âš ï¸ {filename} í¬ë¡­ ì‹¤íŒ¨ (ì˜ì—­ í¬ê¸°ê°€ 0).")
                continue

            try:
                cv2.imwrite(save_path, cropped_img)
                print(f"    - âœ… {filename} ì €ì¥ ì™„ë£Œ.")
            except Exception as e:
                print(f"    - âŒ {filename} ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    print("=== ë‹¨ìˆœí™”ëœ Pointer-Arrow-Target ê°ì²´ íƒì§€ ì‹œìŠ¤í…œ ===")
    image = cv2.imread(IMAGE_PATH)
    if image is None:
        print(f"ì˜¤ë¥˜: ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨. '{IMAGE_PATH}' ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    print(f"ì´ë¯¸ì§€ í¬ê¸°: {image.shape}")
    print(f"ì„¤ì • - ì‹ ë¢°ë„: {CONFIDENCE_THRESHOLD}, ìµœì†Œë©´ì : {MIN_BOX_AREA}")

    detections = detect_objects_yolo(image, model)

    if not detections['target_objects']:
        print("\nâš ï¸  Target ê°ì²´ê°€ íƒì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë” ê´€ëŒ€í•œ ì„¤ì •ìœ¼ë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
        retry_detections = detect_objects_yolo(image, model, conf_threshold=0.001, min_area=10)

        if retry_detections['target_objects']:
            print(f"âœ… ì¬ì‹œë„ì—ì„œ target ê°ì²´ {len(retry_detections['target_objects'])}ê°œ ë°œê²¬!")
            if not detections['pointers'] and retry_detections['pointers']:
                detections['pointers'] = retry_detections['pointers']
            if not detections['arrows'] and retry_detections['arrows']:
                detections['arrows'] = retry_detections['arrows']
            detections['target_objects'] = retry_detections['target_objects']

    recognize_pointer_text(image, detections['pointers'])

    print("\n" + "="*60)
    print("ìµœì¢… íƒì§€ ê²°ê³¼ ìš”ì•½")
    print("="*60)

    total_objects = sum(len(items) for items in detections.values())
    print(f"ì´ íƒì§€ëœ ê°ì²´ ìˆ˜: {total_objects}ê°œ")

    for category, items in detections.items():
        print(f"\nğŸ“‹ {category.replace('_', ' ').capitalize()}: {len(items)}ê°œ")
        for i, item in enumerate(items):
            if category == 'pointers' and 'text' in item:
                print(f"  - {category[:-1]}_{i}: '{item['text']}' (ì‹ ë¢°ë„: {item['confidence']:.3f})")
            else:
                print(f"  - {category[:-1]}_{i}: {item['original_class']} (ì‹ ë¢°ë„: {item['confidence']:.3f})")

    print(f"\n{'-'*40}\nJSON ê²°ê³¼ ìƒì„± ë° ì €ì¥\n{'-'*40}")
    
    json_data = {}
    for category, items in detections.items():
        json_data[category] = []
        for i, item in enumerate(items):
            obj_data = {
                'id': f"{category[:-1]}_{i}",
                'class': item['original_class'],
                'confidence': round(item['confidence'], 3),
                'box': item['box']
            }
            if category == 'pointers' and 'text' in item:
                obj_data['text'] = item['text']
                obj_data['text_confidence'] = round(item.get('text_confidence', 0), 3)
            json_data[category].append(obj_data)
    
    json_output = json.dumps(json_data, indent=2, ensure_ascii=False)
    print("--- JSON ë‚´ìš© ---")
    print(json_output)

    try:
        with open(JSON_SAVE_PATH, 'w', encoding='utf-8') as f:
            f.write(json_output)
        print(f"\nâœ… JSON ê²°ê³¼ê°€ íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {JSON_SAVE_PATH}")
    except Exception as e:
        print(f"\nâŒ JSON íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    save_extracted_objects(image, detections, json_data, CROPPED_OBJECTS_DIR)

    result_image = visualize_detections(image, detections)
    
    cv2.imshow("Object Detection Result", result_image)
    print(f"\nê²°ê³¼ ì°½ì´ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")
    cv2.waitKey(0)
    
    try:
        cv2.imwrite(VISUALIZED_IMAGE_SAVE_PATH, result_image)
        print(f"ì‹œê°í™”ëœ ê²°ê³¼ ì´ë¯¸ì§€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {VISUALIZED_IMAGE_SAVE_PATH}")
    except Exception as e:
        print(f"ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")

    cv2.destroyAllWindows()


if __name__ == "__main__":
    main()